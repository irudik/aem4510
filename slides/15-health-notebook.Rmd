---
title: "Lecture 13"
subtitle: "Health // Difference-in-differences"
author: Ivan Rudik
date: AEM 6510
output: 
  html_document:
  theme: flatly
  highlight: haddock
  code_folding: show
  toc: yes
  toc_depth: 4
  toc_float: yes
  keep_md: true
---

<style type="text/css">
.main-container {
  max-width: 1000px;
  margin-left: auto;
  margin-right: auto;
}
</style>
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi = 300)
```

## R packages 

Required packages: `ggthemes, fixest, broom, modelsummary, tidyverse`

```{r libs}
# load required packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  ggthemes, fixest, broom, modelsummary, tidyverse
)
```

```{r, echo = FALSE}
options(dplyr.summarise.inform = FALSE)
theme_regular <- 
  theme_minimal() +
  theme(
    legend.position = "none",
    title = element_text(size = 14),
    axis.text.x = element_text(size = 14), axis.text.y = element_text(size = 14),
    axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14),
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_line(),
    axis.line = element_line(colour = "black")
  ) 
```

# Hands on: Intro to difference-in-differences

## Generating fake data

To see how DD works in practice we will first generate a fake dataset where **we know the true value of what we want to estimate.** 
This is a good skill to have in order to make sure you understand how methods work, and that your code does what you want it to do.
If you know what the result is and your code produces something different, your code is wrong.

To generate fake data we need to model the **true data generating process.** 
We will make this exactly the DD model, but with some added noise.

### Random numbers
Any time you introduce randomness into your code, you will want to set a random number generator seed so it is reproducible.

```{r}
# Initialize RNG
set.seed(123456)
```

Every time you run this notebook you will get the exact same results even though we are drawing "random" numbers.

### The model parameters

The model generating our data will be very simple:
1. A time-invariant factor specific to both NY and PA
2. A period-specific factor common across both NY and PA
3. A treatment effect in NY after the fake policy is implemented
4. Some added random noise in outcomes

First we need to define the time-invariant factors.

```{r}
# Fixed state characteristics: ny has more biodiversity
state_fes <- tribble(~state, ~state_fe,
                     "NY", 88,
                     "PA", 44)
```

Here we used a `tribble`, which is just a `tibble` but where we can write it out element-by-element.
This is helpful when you need to initialize small data frames.

Next we need the common, period-specific factors.

```{r}
# Period characteristics: biodiversity is declining
period_fes <- tribble(~period, ~period_fe,
                     "before", 341,
                     "after", 207)
```

Last, we need to define the size of the treatment effect.

```{r}
# True effect of the policy: how many additional species are saved?
treatment_effect <- 55
```

Now we have defined all the parameters required to generate our data. 
Next, we need to *actually* generate the data.
This takes a few steps.

### Generating the data

First, we need to generate N observations for each combination of before/after and NY/PA. We can do this with `crossing`.

```{r}
# All combos of states, periods, and observation numbers
bio_df <- crossing(
  state = c("NY", "PA"),
  period = c("before", "after"),
  obs = 1:500
)
bio_df
```

Second, we need to bring in the time-invariant, and period-specific factors with `join` functions.

```{r}
bio_df <- bio_df %>%
  inner_join(period_fes) %>% 
  inner_join(state_fes)
bio_df
```

Third, it will be helpful to define a variable for units that are treated: New York and after.

```{r}
bio_df <- bio_df %>% 
  mutate(treated = state == "NY" & period == "after",
         period = factor(period, levels = c("before", "after")),
         period = relevel(period, "before"))
bio_df
```

Now we need to generate our data by adding the time-invariant effect `state_fe`, the period-specific effect `period_fe`, and some random noise given by `rnorm`. If the observation is New York after the policy we will also add `treatment_effect`.

```{r}
bio_df <- bio_df %>% 
  mutate(
    biodiversity = ifelse(
      treated,
      period_fe + state_fe + treatment_effect + 100*rnorm(n()),
      period_fe + state_fe  + 100*rnorm(n())
    )
  )
bio_df
```

## Raw data

Let's plot the data. New York is in black, Pennsylvania is in orange.
We're using `geom_jitter` horizontally (`height  = 0`) so we can better see the variation in the data.

```{r}

# Switch the order of the period variables so before comes first
bio_df$period = factor(bio_df$period, levels = c("before", "after"))

ggplot(bio_df, group = interaction(state, period)) +
  geom_jitter(aes(x = period, y = biodiversity, color = interaction(state), shape = interaction(state), height = 0), size = 3) +
  annotate("text", size = 8, label = "NY", x = 1, y = 700) +
  annotate("text", size = 8, label = "PA", x = 1, y = 100, color = "orange") +
  scale_color_colorblind() +
  theme_minimal() +
  scale_x_discrete(labels = c("Before Treatment", "After Treatment")) + 
  scale_y_continuous(limits = c(50, 700)) +
  labs(
    x = "Time",
    y = "Biodiversity",
    title = "The raw fake data"
  ) +
  theme_regular
```

Notice that you can clearly see the decreasing time trend (before is higher than after), and also that NY tends to always have higher biodiversity than PA (black higher than orange).
Seeing the effect in just the pure raw data is tricky here without taking means.
Later in the slides we will walk through DD step-by-step and see how it works.
For now we will just directly go to estimating the effect using DD and the `fixest::feols` package.

## Difference-in-differences

```{r}
# Outcome ~ treatment + period fixed effect + state fixed effect, data
estimates <- fixest::feols(
  biodiversity ~ treated + period + state, 
  data = bio_df
) 

msummary(estimates, # report estimates in a table
    coef_map = c(
      "statePA" = "Pennsylvania",
      "periodafter" = "After",
      "treatedTRUE" = "New York & After (Treatment Effect)"
    ),
    gof_omit = "R2|AIC|BIC|Log.|FE|Std.|Obs",
    stars = TRUE,
    fmt = "%.2f",
    title = "The effect of the NY policy on biodiversity",
  )
```

Now compare the true values (left) versus the estimates (right). **DD correctly recovers the true treatment effect (with some noise)!**

```{r}
coefs <- estimates$coefficients
c(treatment_effect, coefs[2]) # treatment_effect
c(period_fes$period_fe[period_fes$period == "after"] - period_fes$period_fe[period_fes$period == "before"], coefs[3]) # period_after
c(state_fes$state_fe[state_fes$state == "PA"] - state_fes$state_fe[state_fes$state == "NY"], coefs[4]) # statePA

```

### DD addresses time-invariant and common period-specific factors

Now let's look at what happens if take more naive approaches that do not address time-invariant factors, or common-period specific factors.
We will look at how the failure to address these things biases our estimates of the effect of the policy in predictable ways.

Suppose we just regressed biodiversity on the existence of the conservation policy.

```{r}
# Outcome ~ treatment, data
fixest::feols(
  biodiversity ~ treated, 
  data = bio_df
  ) %>%  # use the BLL data frame
  msummary( # report estimates in a table
  coef_map = c(
    "periodafter" = "After",
    "treatedTRUE" = "New York & After (Treatment Effect)"
  ),
  gof_omit = "R2|AIC|BIC|Log.|FE|Std.|Obs",
  stars = TRUE,
  fmt = "%.2f",
  title = "The effect of the NY policy on biodiversity",
  )
```

We **underestimate the true effect** (and in fact have an estimate with the wrong sign!) because we did not difference out the common decline in biodiversity over time.
The estimated effect of the policy in NY is confounded by the common decline in biodiversity across both states.
If we took this estimate at face value it says that conservation policies backfire and make biodiversity worse.

What if now we controlled for these common, period-specific factors?

```{r}
# Outcome ~ treatment + period fixed effects, data
fixest::feols(
  biodiversity ~ treated + period, 
  data = bio_df
  ) %>%  # use the BLL data frame
  msummary( # report estimates in a table
  coef_map = c(
    "periodafter" = "After",
    "treatedTRUE" = "New York & After (Treatment Effect)"
  ),
  gof_omit = "R2|AIC|BIC|Log.|FE|Std.|Obs",
  stars = TRUE,
  fmt = "%.2f",
  title = "The effect of the NY policy on biodiversity",
  )
```

Now we **overestimate the true effect**.
We (still) did not difference out the fact that NY tends to have higher levels of biodiversity.
The estimated treatment effect is biased upward because NY is just more biodiverse even without the policy.
We are overstating the impact of the policy because it happened to be adopted by a state with a lot of biodiversity.


# Hands on: Hollingsworth and Rudik (2021)

Now lets work through the HR data to see how they got their results.
We will just start with the cleaned data instead of raw.
Cleaning the data is a huge chunk of the actual work of doing research (90%+), but takes a lot of code/time and is outside the scope of this class.

## Lead poisoning

First, load the lead poisoning data and look at it.
```{r}
## Read in blood lead data
bll_df <- read.csv("data/hr_2021_bll.csv") %>% as_tibble()
bll_df
```

What are the key variables?

- `state`: state fips code
- `county`: county fips code
- `state_county`: full fips code
- `year`: the year
- `ihs_bll`: inverse hyperbolic sine of the lead poisoning rate
- `race`: categorical variable equal to 2 if a treatment county, 1 if a border county, 0 if a control county

### The raw data

First, let's plot the raw data.
This is something you should generally always do.
It lets you see what is actually happening, whether you made data cleaning errors, etc.
If what you're trying to estimate clearly pops outs in the raw data that's a good sign.

Here we will be plotting the raw data with two changes:
1. Only plot for 2005-2009. After 2009 some counties stop reporting lead poisoning, so the composition of the sample changes, making the comparison tricky.
2. Plot the *weighted mean* lead poisoning rate where we weight by the number of children tested. First, we want to plot a mean so we can more clearly see any trends and differences across treated and control counties. Second, we want a *weighted* mean because counties with more testing report estimated rates that less noisy measures of the true rate. We want these counties to count more toward our nationwide average.

```{r}
bll_df %>% 
  group_by(race, year) %>% 
  summarise(percent_high_conditional_tested = weighted.mean(percent_high_conditional_tested, weight, na.rm = T)) %>% 
  filter(year >= 2005 & year <= 2009) %>% 
  ggplot(aes(x = year, y = percent_high_conditional_tested)) +
    geom_vline(xintercept = 2006.5, color = "grey55", linetype = "dashed") +
    geom_point(aes(shape = as.factor(race), color = as.factor(race)), size = 5) + 
    # everything below this line is to just make the plot look cleaner/fancier
    annotate("text", size = 4, label = "Treated", x = 2005.25, y = 2.85) +
    annotate("text", size = 4, label = "Border", x = 2005.25, y = 2.5) +
    annotate("text", size = 4, label = "Control", x = 2005.25, y = 1.4) +
    annotate("text", size = 6, label = "Leaded Fuel", x = 2005.50, y = 0.25) +
    annotate("text", size = 6, label = "Unleaded Fuel", x = 2008, y = 0.25) +
    scale_color_colorblind() +
    labs(
      x = "Year",
      y = "Percent Lead Poisoned",
      title = "Average lead poisoning rates by type (balanced panel)"
    ) +
    theme_regular
```

Before the policy, we have parallel-ish pre-trends across the three groups.
This is a good sign for the validity of the DD approach.
In the post period, we see that treated and border county lead poisoning rates drop relative to control counties, and then stay on the same trend thereafter.
Treated counties drop more than border counties.
All of this indicates that the removal of lead in 2007 had an effect on lead poisoning rates, and that being close to a lead source is worse (good sanity check).

### Difference-in-differences

Now let's actually estimate the effect it had on lead poisoning rates. 
HR uses a DD design in their appendix. 
Let's estimate the effect corresponding to their Table A8 Column 1.
We will regress the inverse hyperbolic sine (approximation to log when you have a lot to zeros) on:
- County fixed effects (county time-invariant characteristics)
- Year fixed effects (common period-specific characteristics)
- County type by period (`as.factor(race)*I(year < 2007)`), this is the treatment variable



```{r}
## Difference-in-differences estimate
fixest::feols(
  ihs_bll ~ as.factor(race)*I(year < 2007) | state_county + year, 
  weights = ~weight, # Weight by number of children tested
  data = bll_df) %>%  # use the BLL data frame
  msummary( # report estimates in a table
  cluster = c("state_county"),
  coef_map = c(
    "as.factor(race)2:I(year < 2007)TRUE" = "Treated",
    "as.factor(race)1:I(year < 2007)TRUE" = "Border"
  ),
  gof_omit = "R2|AIC|BIC|Log.|FE|Std.|Obs",
  stars = TRUE,
  fmt = "%.2f",
  title = "The effect of being in a treated or border county on lead poisoning rates",
  notes = list("Robust standard errors are clustered at the county level.")
)
```

What do our estimates tell us? That counties with leaded racing have higher rates of lead poisoning than border counties (0.22 > 0.09), when have higher rates than control counties (0.09 > 0).
There is enough of a treatment of lead from racing for it to show up in people's blood tests.

### Event study

With raw data, you need to hone down to a balanced panel.
If you actually estimate the event study, you can use the full unbalanced panel dataset.
Now let's estimate the event study.
The event study regression is:
$$\text{ihs(lead poisoned})_{cy} = \sum_{y \neq 2007}\beta^b_y 1(\text{race in border county})_{cy} + \sum_{y \neq 2007}\beta^r_y 1(\text{race in county})_{cy} + \text{controls} + \text{year fixed effects} + \text{county fixed effects}$$

In an event study, we estimate effects of being in the treatment group **in every year relative to some omitted year** (here 2007).
Event studies make for nice plots so we are going to skip the table and go straight to plotting the effects.

```{r}
########################################
## Event study

# Need to factor year so we can omit 2007
bll_df$year <- factor(bll_df$year, ordered = FALSE)
bll_df$year <- relevel(bll_df$year, 3)

# Estimate event study
event_study <- fixest::feols(
  ihs_bll ~ as.factor(race)*year + 
    as.factor(state)*year + 
    unemp_rate + median_income + percent_non_white + lead_emitted + ap | state_county + year, 
  weights = ~weight,
  data = bll_df) %>% 
  tidy(cluster = "state") %>% 
  filter(str_detect(term, "^as.factor\\(race\\)2:year")) %>% 
  add_row(estimate = 0, std.error = 0, .after = 2) %>% 
  mutate(year = row_number() + 2004)

# Plot event study
ggplot(data = event_study, aes(x = year, y = estimate)) +
  geom_hline(yintercept = 0, size = 0.5) +
  geom_vline(xintercept = 2006.5, color = "grey55", linetype = "dashed") +
  geom_ribbon(aes(ymin = estimate - 1.96*std.error, ymax = estimate + 1.96*std.error), 
              fill = "darkslateblue", alpha = 0.4) +
  geom_line(size = 1) +
  geom_point(size = 5) +
  annotate("text", size = 4, label = "Leaded Fuel", x = 2005.50, y = -0.26) +
  annotate("text", size = 4, label = "Unleaded Fuel", x = 2012, y = -0.26) +
  scale_x_continuous(breaks = seq(2005, 2015, 2)) +
  scale_color_colorblind() +
  labs(
    x = "Year",
    y = "Percent Lead Poisoned",
    title = "Percent lead poisoned relative to 2007 (first unleaded year)"
  ) +
  theme_regular
```
What is the event study telling us?
That lead poisoning rates were higher in 2005 and 2006 relative to 2007 in race counties.
Also that the trend in race counties was relatively flat compared to control counties (2005 and 2006 estimates are about the same, also there were a few unleaded races in 2006 so a slight dip is expected).
This is our parallel pre-trends assumption.
Once lead was removed in 2007, the effect of being in a treatment county drops.
The trend after 2007 is flat: control and treatment counties are on parallel trends in the post-period.

One drawback with the lead poisoning data is we only have 2 pre-periods. 
This makes it hard to see whether we do have parallel pre-trends.

## Elderly mortality

Now let's switch to looking at all-cause elderly mortality.
First, load the data.
```{r}
########################################
## Read in mortality data
mortality_df <- read.csv("data/hr_2021_mortality.csv") %>% as_tibble()
mortality_df
```

What are the key variables?

- `state`: state fips code
- `county`: county fips code
- `state_county`: full fips code
- `year`: the year
- `age_adjusted_rate`: age-adjusted mortality rate
- `race`: categorical variable equal to 2 if a treatment county, 1 if a border county, 0 if a control county

The paper plots the raw data but it's kind of hard to see what's going on because mortality rates are declining so quickly.
We are going to jump right into the DD and event studies.
Feel free to try to reproduce their Figure 6 raw data plot using the same approach above.

```{r}
## Difference-in-differences estimate
fixest::feols(
  age_adjusted_rate ~ as.factor(race)*I(year < 2007) | state_county + year, 
  weights = ~weight, # Weight by number of children tested
  data = mortality_df) %>%  # use the BLL data frame
  msummary( # report estimates in a table
  cluster = c("state_county"),
  coef_map = c(
    "as.factor(race)2:I(year < 2007)TRUE" = "Treated",
    "as.factor(race)1:I(year < 2007)TRUE" = "Border"
  ),
  gof_omit = "R2|AIC|BIC|Log.|FE|Std.|Obs",
  stars = TRUE,
  fmt = "%.2f",
  title = "The effect of being in a treated or border county on elderly mortality",
  notes = list("Robust standard errors are clustered at the county level.")
)
```
Being exposed to lead in-county raises mortality rates by 121 per 100,000 elderly, and being exposed to lead in a bordering county only raises it by 70 per 100,000.
Now let's plot the event study similarly to how we did lead poisoning.

```{r}
# Need to factor year so we can omit 2007
mortality_df$year <- factor(mortality_df$year, ordered = FALSE)
mortality_df$year <- relevel(mortality_df$year, 9)

# Estimate event study
event_study <- fixest::feols(
  age_adjusted_rate ~ as.factor(race)*year + 
    as.factor(state)*year + 
    unemp_rate + median_income + percent_non_white + lead_emitted + ap | state_county + year, 
  weights = ~weight,
  data = mortality_df) %>% 
  broom::tidy(cluster = "state") %>% 
  filter(str_detect(term, "^as.factor\\(race\\)2:year")) %>% 
  add_row(estimate = 0, std.error = 0, .after = 8) %>% 
  mutate(year = row_number() + 1998)

# Plot event study
ggplot(data = event_study, aes(x = year, y = estimate)) +
  geom_hline(yintercept = 0, size = 0.5) +
  geom_vline(xintercept = 2006.5, color = "grey55", linetype = "dashed") +
  geom_ribbon(aes(ymin = estimate - 1.96*std.error, ymax = estimate + 1.96*std.error), 
              fill = "darkslateblue", alpha = 0.4) +
  geom_line(size = 1) +
  geom_point(size = 5) +
  annotate("text", size = 4, label = "Leaded Fuel", x = 2002, y = -200) +
  annotate("text", size = 4, label = "Unleaded Fuel", x = 2012, y = -200) +
  scale_x_continuous(breaks = seq(1999, 2015, 2)) +
  scale_color_colorblind() +
  labs(
    x = "Year",
    y = "Age-Adjusted Mortality Rate (deaths per 100,000)",
    title = "Mortality rate relative to 2007 (first unleaded year)"
  ) +
  theme_regular
```

The event study plots the effect of being in a treated county relative to a control county by year.
One of the nice benefits of the mortality data is that there is a longer pre-period: we can clearly see that there are parallel pre-trends.
After 2007, there is a drop in the trend: mortality rates declined in treatment counties relative to control counties.